{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6909860,"sourceType":"datasetVersion","datasetId":3968241},{"sourceId":14057896,"sourceType":"datasetVersion","datasetId":8947711},{"sourceId":14121195,"sourceType":"datasetVersion","datasetId":8996458},{"sourceId":280550089,"sourceType":"kernelVersion"},{"sourceId":281119483,"sourceType":"kernelVersion"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Installing python language tool","metadata":{}},{"cell_type":"code","source":"!pip install -q /kaggle/input/language-tool-python-2-7-1/language_tool_python-2.7.1-py3-none-any.whl","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-12T06:25:44.061549Z","iopub.execute_input":"2025-12-12T06:25:44.062227Z","iopub.status.idle":"2025-12-12T06:25:49.958778Z","shell.execute_reply.started":"2025-12-12T06:25:44.062194Z","shell.execute_reply":"2025-12-12T06:25:49.957534Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# %% Directory settings\n\n# ====================================================\n# Directory settings\n# ====================================================\nfrom pathlib import Path\nimport re\n\nINPUT_DIR = Path(\"../input/\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T06:25:49.960552Z","iopub.execute_input":"2025-12-12T06:25:49.960890Z","iopub.status.idle":"2025-12-12T06:25:49.966227Z","shell.execute_reply.started":"2025-12-12T06:25:49.960852Z","shell.execute_reply":"2025-12-12T06:25:49.965286Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import os\nimport zipfile\nfrom zipfile import ZipFile\nimport shutil\n\n# create download path\ndef get_language_tool_cache_path():\n    # Get download path from environment or use default.\n    download_path = os.environ.get(\n        'LTP_PATH',\n        os.path.join(os.path.expanduser(\"~\"), \".cache\", \"language_tool_python\")\n    )\n    # Make download path, if it doesn't exist.\n    os.makedirs(download_path, exist_ok=True)\n    return download_path\n\nlt_path = get_language_tool_cache_path()\nlt_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T06:25:49.967143Z","iopub.execute_input":"2025-12-12T06:25:49.967414Z","iopub.status.idle":"2025-12-12T06:25:49.990059Z","shell.execute_reply.started":"2025-12-12T06:25:49.967393Z","shell.execute_reply":"2025-12-12T06:25:49.988955Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'/root/.cache/language_tool_python'"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"#cant move files directly from input to cache, so we zip it to output and unzip again\n\n\ndef get_all_file_paths(directory):\n  \n    # initializing empty file paths list\n    file_paths = []\n  \n    # crawling through directory and subdirectories\n    for root, directories, files in os.walk(directory):\n        for filename in files:\n            # join the two strings in order to form the full filepath.\n            filepath = os.path.join(root, filename)\n            file_paths.append(filepath)\n  \n    # returning all file paths\n    return file_paths        \n  \ndef main():\n    # path to folder which needs to be zipped\n    directory = '../input/language-tool-python-2-7-1/LanguageTool-5.7/LanguageTool-5.7'\n  \n    # calling function to get all file paths in the directory\n    file_paths = get_all_file_paths(directory)\n\n    # writing files to a zipfile\n    with ZipFile('./lt.zip','w') as zip:\n        # writing each file one by one\n        for file in file_paths:\n            zip.write(file)\n  \n    print('All files zipped successfully!')        \n    \nmain()\n\n\n \nzip_file = \"./lt.zip\"\n \ntry:\n    with zipfile.ZipFile(zip_file) as z:\n        z.extractall()\n        print(\"Extracted all\")\nexcept:\n    print(\"Invalid file\")\n    \n#move to cache\n!mv {'./input/language-tool-python-2-7-1/LanguageTool-5.7/LanguageTool-5.7'} {lt_path} \nprint(os.listdir('/root/.cache/language_tool_python/'))\n\n#remove files from output\n\nshutil.rmtree('./input')\nos.remove(\"./lt.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T06:25:49.991311Z","iopub.execute_input":"2025-12-12T06:25:49.991635Z","iopub.status.idle":"2025-12-12T06:26:02.667013Z","shell.execute_reply.started":"2025-12-12T06:25:49.991581Z","shell.execute_reply":"2025-12-12T06:26:02.665922Z"}},"outputs":[{"name":"stdout","text":"All files zipped successfully!\nExtracted all\n['LanguageTool-5.7']\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!pip install textstat -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T06:26:02.669804Z","iopub.execute_input":"2025-12-12T06:26:02.670716Z","iopub.status.idle":"2025-12-12T06:26:08.353750Z","shell.execute_reply.started":"2025-12-12T06:26:02.670675Z","shell.execute_reply":"2025-12-12T06:26:08.352681Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('/kaggle/input/clean-samples-from-new-llms-300/new_data.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T06:26:08.354981Z","iopub.execute_input":"2025-12-12T06:26:08.355258Z","iopub.status.idle":"2025-12-12T06:26:08.735845Z","shell.execute_reply.started":"2025-12-12T06:26:08.355230Z","shell.execute_reply":"2025-12-12T06:26:08.735069Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import polars as pl\nimport re\nimport string\nfrom collections import Counter\nfrom textblob import TextBlob\nimport textstat\nimport spacy\nfrom scipy.stats import entropy\nimport gzip\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import sent_tokenize\nfrom textblob import TextBlob\nimport numpy as np\n# from nltk.corpus import stopwords\n\n# Load data\n# train_df = pl.read_csv('/kaggle/input/pan-cief/train.csv')\n# test_df = pl.read_csv('/kaggle/input/pan-cief/val.csv')\n\n# Initialize spacy and stopwords\nnlp = spacy.load(\"en_core_web_sm\")\nstop_words = set(stopwords.words('english'))\n\n# Define all feature functions\ndef vocabSize(sentence):\n    doc = nlp(sentence.lower())\n    tokens = set([token.text for token in doc if not token.is_punct])\n    return len(tokens)\n\ndef sentence_complexity(sentence):\n    flesch_score = textstat.flesch_reading_ease(sentence)\n    fk_grade_level = textstat.flesch_kincaid_grade(sentence)\n    gunning_fog = textstat.gunning_fog(sentence)\n    smog_index = textstat.smog_index(sentence)\n    composite_score = (flesch_score * 0.2 + fk_grade_level * 0.3 + \n                      gunning_fog * 0.3 + smog_index * 0.2)\n    return composite_score\n\ndef punctuation_count(paragraph):\n    return sum(1 for char in paragraph if char in string.punctuation)\n\ndef sentence_length_difference(paragraph):\n    sentences = re.split(r'[.!?]', paragraph)\n    sentences = [s.strip() for s in sentences if s.strip()]\n    if not sentences:\n        return 0\n    sentence_lengths = [len(s.split()) for s in sentences]\n    return max(sentence_lengths) - min(sentence_lengths)\n\ndef type_token_ratio(text):\n    words = text.split()\n    if len(words) == 0:\n        return 0\n    unique_words = set(words)\n    return len(unique_words) / len(words)\n\ndef pos_counts(text):\n    doc = nlp(text)\n    pos_count_dict = {}\n    for token in doc:\n        pos = token.pos_\n        pos_count_dict[pos] = pos_count_dict.get(pos, 0) + 1\n    return pos_count_dict\n\ndef count_discourse_markers(text):\n    discourse_markers = [\"however\", \"therefore\", \"although\", \"nevertheless\", \"hence\"]\n    return sum(text.lower().count(marker) for marker in discourse_markers)\n\ndef word_entropy(text):\n    doc = nlp(text)\n    words = [t.lemma_.lower() for t in doc if t.is_alpha]\n    if not words:\n        return 0\n    freqs = list(Counter(words).values())\n    return entropy(freqs)\n\ndef flesch_reading_ease(text):\n    try:\n        return textstat.flesch_reading_ease(text)\n    except:\n        return 0\n\ndef gzip_ratio(text):\n    if len(text) == 0:\n        return 0\n    compressed = len(gzip.compress(text.encode('utf-8')))\n    return compressed / len(text)\n\ndef negation_frequency(text):\n    doc = nlp(text)\n    negations = [t for t in doc if t.dep_ == \"neg\" or \n                 t.lemma_.lower() in [\"not\", \"no\", \"never\", \"none\", \"n't\"]]\n    total_words = len([t for t in doc if t.is_alpha])\n    return len(negations) / (total_words + 1e-5)\n\ndef question_statement_ratio(text):\n    doc = nlp(text)\n    sentences = list(doc.sents)\n    if not sentences:\n        return 0\n    question_count = sum(1 for s in sentences if s.text.strip().endswith(\"?\"))\n    statement_count = sum(1 for s in sentences if s.text.strip().endswith(\".\"))\n    return question_count / (statement_count + 1e-5)\n\ndef clause_to_sentence_ratio(text):\n    doc = nlp(text)\n    sentences = list(doc.sents)\n    if not sentences:\n        return 0\n    clause_markers = (\"mark\", \"advcl\", \"ccomp\", \"xcomp\", \"acl\", \"relcl\", \"conj\")\n    clause_count = sum(1 for t in doc if t.dep_ in clause_markers)\n    return clause_count / len(sentences)\n\ndef modal_verb_frequency(text):\n    doc = nlp(text)\n    modals = {\"can\", \"could\", \"may\", \"might\", \"shall\", \"should\", \"will\", \"would\", \"must\"}\n    modal_count = sum(1 for t in doc if t.lemma_.lower() in modals)\n    total_words = len([t for t in doc if t.is_alpha])\n    return modal_count / (total_words + 1e-5)\n\ndef pronoun_ratio(text):\n    doc = nlp(text)\n    pronouns = [t for t in doc if t.pos_ == \"PRON\"]\n    total_words = len([t for t in doc if t.is_alpha])\n    return len(pronouns) / (total_words + 1e-5)\n\ndef pos_diversity(text):\n    doc = nlp(text)\n    pos_tags = [t.pos_ for t in doc if t.is_alpha]\n    if not pos_tags:\n        return 0\n    counts = Counter(pos_tags)\n    return entropy(list(counts.values()))\n\ndef hapax_legomena_ratio(text):\n    doc = nlp(text)\n    words = [t.lemma_.lower() for t in doc if t.is_alpha]\n    if not words:\n        return 0\n    freqs = Counter(words)\n    hapax = sum(1 for w, f in freqs.items() if f == 1)\n    return hapax / len(freqs)\n\ndef get_sentiment_polarity(text):\n    return TextBlob(text).sentiment.polarity\n\ndef get_sentiment_subjectivity(text):\n    return TextBlob(text).sentiment.subjectivity\n\ndef count_stopwords(text):\n    return len([word for word in text.split() if word.lower() in stop_words])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T06:26:08.736960Z","iopub.execute_input":"2025-12-12T06:26:08.737324Z","iopub.status.idle":"2025-12-12T06:26:21.398137Z","shell.execute_reply.started":"2025-12-12T06:26:08.737294Z","shell.execute_reply":"2025-12-12T06:26:21.397343Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from nltk.tokenize import sent_tokenize\nfrom collections import Counter\nimport spacy\nimport re\nfrom textblob import Word\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom collections import Counter\nimport math\n\nnlp = spacy.load(\"en_core_web_sm\")\n\ndef sentence_length_variation(text):\n    sentences = sent_tokenize(text)\n    lengths = [len(s.split()) for s in sentences if len(s.split()) > 0]\n\n    if len(lengths) < 2:\n        return 0.0  \n\n    return np.std(lengths)   # Standard deviation\n\n# def vocabulary_diversity(text): ## same as type token ratio\n#     words = [w.lower() for w in text.split() if w.isalpha()]\n#     if len(words) == 0:\n#         return 0\n#     return len(set(words)) / len(words)\n\ndef repetition_rate(text):\n    words = [w.lower() for w in text.split()]\n    bigrams = [(words[i], words[i+1]) for i in range(len(words)-1)]\n    if len(bigrams) == 0:\n        return 0\n\n    counts = Counter(bigrams)\n    repeated = sum(1 for bg, c in counts.items() if c > 1)\n\n    return repeated / len(bigrams)\n\ndef personal_voice_score(text):\n    personal_pronouns = {\"i\", \"me\", \"my\", \"mine\", \"we\", \"us\", \"our\", \"ours\"}\n    words = [w.lower() for w in text.split()]\n    count = sum(1 for w in words if w in personal_pronouns)\n    if len(words) == 0:\n        return 0\n    return count / len(words)\n\ndef emotion_variation(text):\n    sentences = sent_tokenize(text)\n    if len(sentences) < 2:\n        return 0\n\n    sentiments = [TextBlob(s).sentiment.polarity for s in sentences]\n    diffs = [abs(sentiments[i] - sentiments[i+1]) for i in range(len(sentiments)-1)]\n\n    return np.mean(diffs)\n\n\ndef specificity_score(text):\n    doc = nlp(text)\n    concrete_tags = {\"NOUN\", \"PROPN\", \"NUM\"}  \n    concrete_count = sum(1 for token in doc if token.pos_ in concrete_tags)\n    if len(doc) == 0:\n        return 0\n    return concrete_count / len(doc)\n\n\ndef imperfection_score(text):\n    words = [w for w in re.findall(r\"\\b\\w+\\b\", text)]\n    if len(words) == 0:\n        return 0\n\n    misspelled = sum(1 for w in words if Word(w).correct().lower() != w.lower())\n    return misspelled / len(words)\n\nfigurative_markers = [\n    \"like\", \"as if\", \"as though\", \"metaphor\", \"symbolic\", \n    \"resembles\", \"reminds me of\", \"figurative\"\n]\n\ndef figurative_language_score(text):\n    t = text.lower()\n    count = sum(t.count(m) for m in figurative_markers)\n    return count\n\ndef paragraph_coherence_consistency(text):\n    paragraphs = [p.strip() for p in text.split(\"\\n\") if len(p.strip()) > 0]\n\n    if len(paragraphs) < 2:\n        return 0\n\n    vec = TfidfVectorizer().fit_transform(paragraphs)\n    sims = []\n\n    for i in range(len(paragraphs)-1):\n        sim = cosine_similarity(vec[i], vec[i+1])[0][0]\n        sims.append(sim)\n\n    return np.mean(sims)\n\n\ndef predictability_score(text):\n    words = [w.lower() for w in text.split()]\n    counts = Counter(words)\n    total = len(words)\n    if total == 0:\n        return 0\n\n    probs = [counts[w]/total for w in words]\n    surprise = [-math.log(p) for p in probs]\n\n    return np.mean(surprise)\n\nhedge_words = {\n    \"maybe\", \"perhaps\", \"sort of\", \"kind of\", \"i guess\", \n    \"probably\", \"possibly\", \"apparently\", \"roughly\"\n}\n\ndef hedge_uncertainty_score(text):\n    t = text.lower()\n    count = sum(t.count(hw) for hw in hedge_words)\n    return count\n\ntransitions = [\n    \"however\", \"therefore\", \"meanwhile\", \"moreover\", \"furthermore\",\n    \"in contrast\", \"on the other hand\", \"overall\", \"in summary\"\n]\n\ndef transition_variety_score(text):\n    t = text.lower()\n    count = sum(t.count(word) for word in transitions)\n    return count","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T06:26:21.399176Z","iopub.execute_input":"2025-12-12T06:26:21.399788Z","iopub.status.idle":"2025-12-12T06:26:22.114190Z","shell.execute_reply.started":"2025-12-12T06:26:21.399754Z","shell.execute_reply":"2025-12-12T06:26:22.113346Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import language_tool_python\n\ntool = language_tool_python.LanguageTool('en-US')\n# nlp = spacy.load(\"en_core_web_sm\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T06:26:22.115235Z","iopub.execute_input":"2025-12-12T06:26:22.115586Z","iopub.status.idle":"2025-12-12T06:26:24.580366Z","shell.execute_reply.started":"2025-12-12T06:26:22.115558Z","shell.execute_reply":"2025-12-12T06:26:24.578173Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def grammatical_mistakes(sentence):\n\n  mistakes = len(tool.check(sentence))\n\n  return mistakes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T06:26:24.581599Z","iopub.execute_input":"2025-12-12T06:26:24.581973Z","iopub.status.idle":"2025-12-12T06:26:24.587322Z","shell.execute_reply.started":"2025-12-12T06:26:24.581942Z","shell.execute_reply":"2025-12-12T06:26:24.586383Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def pos_tag_ngrams(text, n=2):\n    doc = nlp(text)\n    tags = [token.pos_ for token in doc if token.is_alpha]\n\n    if len(tags) < n:\n        return {}\n\n    ngrams = zip(*[tags[i:] for i in range(n)])\n    return Counter(ngrams)\n\ndef pos_ngram_variety(text, n=2):\n    ngrams = pos_tag_ngrams(text, n)\n    return len(ngrams)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T06:26:24.588420Z","iopub.execute_input":"2025-12-12T06:26:24.589009Z","iopub.status.idle":"2025-12-12T06:26:24.605560Z","shell.execute_reply.started":"2025-12-12T06:26:24.588980Z","shell.execute_reply":"2025-12-12T06:26:24.604443Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import pandas as pd\nfrom textblob import TextBlob\n\ndef get_features_from_text(text: str):\n    stop_words = set(stopwords.words('english'))\n    \n    features = {}\n    features['character_count'] = len(text)\n    features['word_count'] = len(text.split())\n    features['sentence_count']=len(sent_tokenize(text))\n    features['paragraph_count'] = len(text.split(\"\\n\"))\n    features['stopword_count'] = len([word for word in text.split() if word.lower() in stop_words])\n    features['unique_word_count'] = len(set(text.split()))\n    features['sentiment_polarity'] = TextBlob(text).sentiment.polarity\n    features['sentiment_subjectivity'] = TextBlob(text).sentiment.subjectivity\n    features['discourse_marker_count'] = count_discourse_markers(text)\n    features['vocab_size'] = vocabSize(text)\n    features['sentence_complexity'] = sentence_complexity(text)\n    features['punctuation_count'] = punctuation_count(text)\n    features['sentence_length_difference'] = sentence_length_difference(text)\n    features['type_token_ratio'] = type_token_ratio(text)\n    features['word_entropy'] = word_entropy(text)\n    features['flesch_reading_ease'] = flesch_reading_ease(text)\n    features['gzip_ratio'] = gzip_ratio(text)\n    features['negation_freq'] = negation_frequency(text)\n    features['question_stmt_ratio'] = question_statement_ratio(text)\n    features['clause_sentence_ratio'] = clause_to_sentence_ratio(text)\n    features['modal_freq'] = modal_verb_frequency(text)\n    features['pronoun_ratio'] = pronoun_ratio(text)\n    features['pos_diversity'] = pos_diversity(text)\n    features['hapax_ratio'] = hapax_legomena_ratio(text)\n    features['sentence_length_variation'] = sentence_length_variation(text)\n    features['repetition_rate'] = repetition_rate(text)\n    features['personal_voice_score'] = personal_voice_score(text)\n    features['emotion_variation'] = emotion_variation(text)\n    features['specificity_score'] = specificity_score(text)\n    features['figurative_language_score'] = figurative_language_score(text)\n    features['paragraph_coherence_consistency'] = paragraph_coherence_consistency(text)\n    features['predictability_score'] = predictability_score(text)\n    features['hedge_uncertainty_score'] = hedge_uncertainty_score(text)\n    features['transition_variety_score'] = transition_variety_score(text)\n    features['grammatical_mistakes'] = grammatical_mistakes(text)\n    features['pos_2gram_variety'] = pos_ngram_variety(text)\n    features['pos_3gram_variety'] = pos_ngram_variety(text,n=3)\n    features['pos_4gram_variety'] = pos_ngram_variety(text,n=4)\n    # features['perplexity'] = perplexity(text)\n    \n    return pd.Series(features)\n\n# Apply the function to create new columns\nnew_features = df['text'].apply(get_features_from_text)\ndf = pd.concat([df, new_features], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T06:26:24.606659Z","iopub.execute_input":"2025-12-12T06:26:24.607301Z","iopub.status.idle":"2025-12-12T06:35:07.025400Z","shell.execute_reply.started":"2025-12-12T06:26:24.607270Z","shell.execute_reply":"2025-12-12T06:35:07.024527Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"FEATURES = ['character_count', 'word_count', 'paragraph_count',\n       'stopword_count', 'unique_word_count', 'sentiment_subjectivity',\n       'discourse_marker_count', 'sentence_complexity', 'punctuation_count',\n       'sentence_length_difference', 'type_token_ratio', 'word_entropy',\n       'flesch_reading_ease', 'gzip_ratio', 'question_stmt_ratio',\n       'clause_sentence_ratio', 'modal_freq', 'pronoun_ratio', 'pos_diversity',\n       'hapax_ratio', 'sentence_length_variation', 'repetition_rate',\n       'specificity_score', 'figurative_language_score',\n       'paragraph_coherence_consistency', 'transition_variety_score',\n       'grammatical_mistakes', 'pos_2gram_variety', 'pos_3gram_variety',\n       'pos_4gram_variety']\n\nTARGET = 'label'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T06:35:07.026308Z","iopub.execute_input":"2025-12-12T06:35:07.026560Z","iopub.status.idle":"2025-12-12T06:35:07.031893Z","shell.execute_reply.started":"2025-12-12T06:35:07.026540Z","shell.execute_reply":"2025-12-12T06:35:07.030902Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import f1_score\nimport numpy as np\nfrom sklearn.base import clone\nfrom xgboost import XGBClassifier\nimport pandas as pd\nimport numpy as np\nfrom gensim.models import Word2Vec\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport re\nimport joblib\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\n\nmodels = {\n    'XGB': XGBClassifier(eval_metric='logloss', random_state=47),\n    'Random Forest': RandomForestClassifier(random_state=47),\n    'Logistic Regression': LogisticRegression(random_state=47),\n    'SVM': SVC(probability=True,random_state=47),    \n}\n\ndef train_and_get_preds(model, train, test):\n    # For binary classification, we want probabilities for both classes\n    # Shape: (n_samples, 2) for probabilities of both classes\n    test_preds = np.zeros((test.shape[0], 2))\n    \n    # Initialize k-fold\n    kf = KFold(n_splits=5, random_state=42, shuffle=True)\n    \n    # Assuming train contains both features and target\n    # Separate features and target\n    X_train = train.drop('label', axis=1)\n    y_train = train['label']\n    \n    # Initialize array for OOF predictions\n    oof_preds = np.zeros((train.shape[0], 2))\n    \n    # Store F1 scores for each fold\n    fold_f1_scores = []\n    \n    # K-fold training and prediction\n    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train)):\n        print(f'Fold {fold+1}')\n        \n        # Split data\n        X_tr = X_train.iloc[train_idx]\n        y_tr = y_train.iloc[train_idx]\n        X_val = X_train.iloc[val_idx]\n        y_val = y_train.iloc[val_idx]\n        \n        # Clone model to avoid contamination between folds\n        fold_model = clone(model)\n        \n        # Train model\n        fold_model.fit(X_tr, y_tr)\n        \n        # Get test predictions (probabilities for both classes)\n        fold_test_preds = fold_model.predict_proba(test)\n        test_preds += fold_test_preds / kf.n_splits  # Average across folds\n        \n        # Get OOF predictions for validation\n        fold_oof_preds = fold_model.predict_proba(X_val)\n        oof_preds[val_idx] = fold_oof_preds\n        \n        # Calculate F1 score for this fold\n        # Convert probabilities to class predictions\n        fold_val_preds = np.argmax(fold_oof_preds, axis=1)\n        fold_f1 = f1_score(y_val, fold_val_preds)\n        fold_f1_scores.append(fold_f1)\n        \n        # Print fold F1 score\n        print(f'  Fold {fold+1} OOF F1 Score: {fold_f1:.4f}')\n    \n    # Calculate and print overall OOF metrics\n    print('\\n' + '='*50)\n    print('Cross-Validation Results:')\n    print('='*50)\n    \n    # Convert all OOF probabilities to class predictions\n    all_oof_preds = np.argmax(oof_preds, axis=1)\n    overall_f1 = f1_score(y_train, all_oof_preds)\n    \n    # Print individual fold F1 scores\n    for fold, score in enumerate(fold_f1_scores):\n        print(f'Fold {fold+1}: F1 = {score:.4f}')\n    \n    # Print mean and std of fold F1 scores\n    mean_f1 = np.mean(fold_f1_scores)\n    std_f1 = np.std(fold_f1_scores)\n    print(f'\\nMean F1: {mean_f1:.4f} (+/- {std_f1:.4f})')\n    print(f'Overall OOF F1: {overall_f1:.4f}')\n    print('='*50)\n    \n    return test_preds, oof_preds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T06:35:07.035058Z","iopub.execute_input":"2025-12-12T06:35:07.035379Z","iopub.status.idle":"2025-12-12T06:36:01.289781Z","shell.execute_reply.started":"2025-12-12T06:35:07.035358Z","shell.execute_reply":"2025-12-12T06:36:01.288885Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"pan_train = pd.read_csv('/kaggle/input/creating-additional-features-for-pan-clef/train.csv')\npan_test = pd.read_csv('/kaggle/input/creating-additional-features-for-pan-clef/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T06:36:01.290733Z","iopub.execute_input":"2025-12-12T06:36:01.291319Z","iopub.status.idle":"2025-12-12T06:36:05.659124Z","shell.execute_reply.started":"2025-12-12T06:36:01.291294Z","shell.execute_reply":"2025-12-12T06:36:05.658215Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"coling_train = pd.read_csv('/kaggle/input/coling-ghostbuster/coling_train_with_features.csv').sample(n=23707,random_state=42)\ncoling_test = pd.read_csv('/kaggle/input/creating-with-new-features-coling/coling_test3000.csv').sample(n=3586,random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T06:36:05.660082Z","iopub.execute_input":"2025-12-12T06:36:05.660350Z","iopub.status.idle":"2025-12-12T06:36:07.170219Z","shell.execute_reply.started":"2025-12-12T06:36:05.660330Z","shell.execute_reply":"2025-12-12T06:36:07.169251Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"pan_test_preds_training_PAN_CLEF,_ = train_and_get_preds(models['XGB'],\n                                                pan_train[FEATURES+[TARGET]],\n                                                pan_test[FEATURES])\n\ncoling_test_preds_training_PAN_CLEF,_ = train_and_get_preds(models['Random Forest'],\n                                                pan_train[FEATURES+[TARGET]],\n                                                coling_test[FEATURES])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T06:47:46.538448Z","iopub.execute_input":"2025-12-12T06:47:46.538795Z","iopub.status.idle":"2025-12-12T06:48:38.842371Z","shell.execute_reply.started":"2025-12-12T06:47:46.538772Z","shell.execute_reply":"2025-12-12T06:48:38.841397Z"}},"outputs":[{"name":"stdout","text":"Fold 1\n  Fold 1 OOF F1 Score: 0.9782\nFold 2\n  Fold 2 OOF F1 Score: 0.9762\nFold 3\n  Fold 3 OOF F1 Score: 0.9789\nFold 4\n  Fold 4 OOF F1 Score: 0.9740\nFold 5\n  Fold 5 OOF F1 Score: 0.9781\n\n==================================================\nCross-Validation Results:\n==================================================\nFold 1: F1 = 0.9782\nFold 2: F1 = 0.9762\nFold 3: F1 = 0.9789\nFold 4: F1 = 0.9740\nFold 5: F1 = 0.9781\n\nMean F1: 0.9771 (+/- 0.0018)\nOverall OOF F1: 0.9771\n==================================================\nFold 1\n  Fold 1 OOF F1 Score: 0.9653\nFold 2\n  Fold 2 OOF F1 Score: 0.9645\nFold 3\n  Fold 3 OOF F1 Score: 0.9649\nFold 4\n  Fold 4 OOF F1 Score: 0.9606\nFold 5\n  Fold 5 OOF F1 Score: 0.9666\n\n==================================================\nCross-Validation Results:\n==================================================\nFold 1: F1 = 0.9653\nFold 2: F1 = 0.9645\nFold 3: F1 = 0.9649\nFold 4: F1 = 0.9606\nFold 5: F1 = 0.9666\n\nMean F1: 0.9644 (+/- 0.0020)\nOverall OOF F1: 0.9644\n==================================================\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"pan_test_preds_training_COLING, gb_essay_oof_preds_training_COLING = train_and_get_preds(models['Random Forest'],\n                                                coling_train[FEATURES+[TARGET]],\n                                                pan_test[FEATURES])\n\ncoling_test_preds_training_COLING, gb_essay_oof_preds_training_COLING = train_and_get_preds(models['Random Forest'],\n                                                coling_train[FEATURES+[TARGET]],\n                                                coling_test[FEATURES])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T06:48:38.843678Z","iopub.execute_input":"2025-12-12T06:48:38.844078Z","iopub.status.idle":"2025-12-12T06:50:05.891364Z","shell.execute_reply.started":"2025-12-12T06:48:38.844055Z","shell.execute_reply":"2025-12-12T06:50:05.890466Z"}},"outputs":[{"name":"stdout","text":"Fold 1\n  Fold 1 OOF F1 Score: 0.8688\nFold 2\n  Fold 2 OOF F1 Score: 0.8685\nFold 3\n  Fold 3 OOF F1 Score: 0.8750\nFold 4\n  Fold 4 OOF F1 Score: 0.8638\nFold 5\n  Fold 5 OOF F1 Score: 0.8703\n\n==================================================\nCross-Validation Results:\n==================================================\nFold 1: F1 = 0.8688\nFold 2: F1 = 0.8685\nFold 3: F1 = 0.8750\nFold 4: F1 = 0.8638\nFold 5: F1 = 0.8703\n\nMean F1: 0.8693 (+/- 0.0036)\nOverall OOF F1: 0.8693\n==================================================\nFold 1\n  Fold 1 OOF F1 Score: 0.8688\nFold 2\n  Fold 2 OOF F1 Score: 0.8685\nFold 3\n  Fold 3 OOF F1 Score: 0.8750\nFold 4\n  Fold 4 OOF F1 Score: 0.8638\nFold 5\n  Fold 5 OOF F1 Score: 0.8703\n\n==================================================\nCross-Validation Results:\n==================================================\nFold 1: F1 = 0.8688\nFold 2: F1 = 0.8685\nFold 3: F1 = 0.8750\nFold 4: F1 = 0.8638\nFold 5: F1 = 0.8703\n\nMean F1: 0.8693 (+/- 0.0036)\nOverall OOF F1: 0.8693\n==================================================\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"pan_test_probs = pd.concat([pd.DataFrame(data=pan_test_preds_training_COLING,columns=[\"prob0_COLING\",\"prob1_COLING\"]),\n          pd.DataFrame(data=pan_test_preds_training_PAN_CLEF,columns=[\"prob0_PAN\",\"prob1_PAN\"])],axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T06:50:22.437585Z","iopub.execute_input":"2025-12-12T06:50:22.438673Z","iopub.status.idle":"2025-12-12T06:50:22.444166Z","shell.execute_reply.started":"2025-12-12T06:50:22.438606Z","shell.execute_reply":"2025-12-12T06:50:22.443254Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"coling_test_probs = pd.concat([pd.DataFrame(data=coling_test_preds_training_COLING,columns=[\"prob0_COLING\",\"prob1_COLING\"]),\n          pd.DataFrame(data=coling_test_preds_training_PAN_CLEF,columns=[\"prob0_PAN\",\"prob1_PAN\"])],axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T06:50:23.396426Z","iopub.execute_input":"2025-12-12T06:50:23.396774Z","iopub.status.idle":"2025-12-12T06:50:23.402993Z","shell.execute_reply.started":"2025-12-12T06:50:23.396753Z","shell.execute_reply":"2025-12-12T06:50:23.401853Z"}},"outputs":[],"execution_count":43},{"cell_type":"markdown","source":"## Training on PAN and predicting on new samples","metadata":{}},{"cell_type":"code","source":"new_samples_test_preds_training_PAN,new_samples_oof_preds_training_PAN = train_and_get_preds(models['XGB'],\n                                                pan_train[FEATURES+[TARGET]],\n                                                df[FEATURES])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T06:36:07.171354Z","iopub.execute_input":"2025-12-12T06:36:07.171601Z","iopub.status.idle":"2025-12-12T06:36:10.251219Z","shell.execute_reply.started":"2025-12-12T06:36:07.171582Z","shell.execute_reply":"2025-12-12T06:36:10.250396Z"}},"outputs":[{"name":"stdout","text":"Fold 1\n  Fold 1 OOF F1 Score: 0.9782\nFold 2\n  Fold 2 OOF F1 Score: 0.9762\nFold 3\n  Fold 3 OOF F1 Score: 0.9789\nFold 4\n  Fold 4 OOF F1 Score: 0.9740\nFold 5\n  Fold 5 OOF F1 Score: 0.9781\n\n==================================================\nCross-Validation Results:\n==================================================\nFold 1: F1 = 0.9782\nFold 2: F1 = 0.9762\nFold 3: F1 = 0.9789\nFold 4: F1 = 0.9740\nFold 5: F1 = 0.9781\n\nMean F1: 0.9771 (+/- 0.0018)\nOverall OOF F1: 0.9771\n==================================================\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"## Training on COLING and predicting on new samples","metadata":{}},{"cell_type":"code","source":"new_samples_test_preds_training_COLING,new_samples_oof_preds_training_COLING = train_and_get_preds(models['XGB'],\n                                                coling_train[FEATURES+[TARGET]],\n                                                df[FEATURES])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T06:36:10.252110Z","iopub.execute_input":"2025-12-12T06:36:10.252391Z","iopub.status.idle":"2025-12-12T06:36:13.025048Z","shell.execute_reply.started":"2025-12-12T06:36:10.252370Z","shell.execute_reply":"2025-12-12T06:36:13.024193Z"}},"outputs":[{"name":"stdout","text":"Fold 1\n  Fold 1 OOF F1 Score: 0.8677\nFold 2\n  Fold 2 OOF F1 Score: 0.8710\nFold 3\n  Fold 3 OOF F1 Score: 0.8765\nFold 4\n  Fold 4 OOF F1 Score: 0.8624\nFold 5\n  Fold 5 OOF F1 Score: 0.8737\n\n==================================================\nCross-Validation Results:\n==================================================\nFold 1: F1 = 0.8677\nFold 2: F1 = 0.8710\nFold 3: F1 = 0.8765\nFold 4: F1 = 0.8624\nFold 5: F1 = 0.8737\n\nMean F1: 0.8703 (+/- 0.0049)\nOverall OOF F1: 0.8703\n==================================================\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"total_preds = pd.concat([pd.DataFrame(data=new_samples_test_preds_training_PAN,columns=[\"prob0_PAN\",\"prob1_PAN\"]),\n                        pd.DataFrame(data=new_samples_test_preds_training_COLING,columns=[\"prob0_COLING\",\"prob1_COLING\"])],axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T06:53:15.494996Z","iopub.execute_input":"2025-12-12T06:53:15.495802Z","iopub.status.idle":"2025-12-12T06:53:15.501107Z","shell.execute_reply.started":"2025-12-12T06:53:15.495775Z","shell.execute_reply":"2025-12-12T06:53:15.500205Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n\ndef calculate_comprehensive_metrics(predictions, true_labels):\n    \"\"\"\n    Calculate comprehensive metrics for each model section\n    \n    Returns:\n    dict: Dictionary containing F1, precision, recall, and accuracy for each model\n    \"\"\"\n    \n    if len(predictions) != 300 or len(true_labels) != 300:\n        raise ValueError(\"Both predictions and true_labels must have exactly 300 elements\")\n    \n    slices = {\n        'Gemini': slice(0, 100),\n        'DeepSeek 3.1': slice(100, 200),\n        'GPT-5': slice(200, 300)\n    }\n    \n    metrics = {}\n    \n    for model_name, slice_obj in slices.items():\n        model_preds = predictions[slice_obj]\n        model_true = true_labels[slice_obj]\n        \n        metrics[model_name] = {\n            'f1': f1_score(model_true, model_preds, pos_label=1),\n            'precision': precision_score(model_true, model_preds, pos_label=1),\n            'recall': recall_score(model_true, model_preds, pos_label=1),\n            'accuracy': accuracy_score(model_true, model_preds),\n            'predicted_ones': np.sum(model_preds == 1),\n            'actual_ones': np.sum(model_true == 1)\n        }\n    \n    # Print results in a nice format\n    print(\"COMPREHENSIVE MODEL PERFORMANCE\")\n    print(\"=\" * 80)\n    for model, scores in metrics.items():\n        print(f\"\\n{model}:\")\n        print(f\"  F1 Score:       {scores['f1']:.4f}\")\n        print(f\"  Precision:      {scores['precision']:.4f}\")\n        print(f\"  Recall:         {scores['recall']:.4f}\")\n        print(f\"  Accuracy:       {scores['accuracy']:.4f}\")\n        print(f\"  Predicted '1's: {scores['predicted_ones']}/100\")\n        print(f\"  Actual '1's:    {scores['actual_ones']}/100\")\n    \n    return metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T06:36:13.034668Z","iopub.execute_input":"2025-12-12T06:36:13.034970Z","iopub.status.idle":"2025-12-12T06:36:13.049431Z","shell.execute_reply.started":"2025-12-12T06:36:13.034949Z","shell.execute_reply":"2025-12-12T06:36:13.048406Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import Ridge\n\ndef get_weighted_score(X_train,y_train,X_test,y_test):\n    # X_train,X_test,y_train,y_test = train_test_split(data,target,test_size=0.8,random_state=42)\n\n    ridge = Ridge()\n    ridge.fit(X_train,y_train)\n    test_probs = ridge.predict(X_test)\n\n    metric_f1 = f1_score(y_test,np.where(test_probs>0.5,1,0))\n    all_metrics = calculate_comprehensive_metrics(np.where(test_probs>0.5,1,0),y_test)\n    print(f\"The f1 score is {metric_f1}.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T06:55:09.515176Z","iopub.execute_input":"2025-12-12T06:55:09.515540Z","iopub.status.idle":"2025-12-12T06:55:09.522411Z","shell.execute_reply.started":"2025-12-12T06:55:09.515519Z","shell.execute_reply":"2025-12-12T06:55:09.521466Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"pron_feats = ['prob0_COLING', 'prob1_COLING', 'prob0_PAN', 'prob1_PAN']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T06:55:10.150520Z","iopub.execute_input":"2025-12-12T06:55:10.151454Z","iopub.status.idle":"2025-12-12T06:55:10.155673Z","shell.execute_reply.started":"2025-12-12T06:55:10.151403Z","shell.execute_reply":"2025-12-12T06:55:10.154700Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"## weighted ensemble from PAN CLEF\nget_weighted_score(pan_test_probs[pron_feats],pan_test['label'],total_preds[pron_feats],df['label'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T06:55:10.355912Z","iopub.execute_input":"2025-12-12T06:55:10.356241Z","iopub.status.idle":"2025-12-12T06:55:10.389439Z","shell.execute_reply.started":"2025-12-12T06:55:10.356217Z","shell.execute_reply":"2025-12-12T06:55:10.388644Z"}},"outputs":[{"name":"stdout","text":"COMPREHENSIVE MODEL PERFORMANCE\n================================================================================\n\nGemini:\n  F1 Score:       0.9418\n  Precision:      1.0000\n  Recall:         0.8900\n  Accuracy:       0.8900\n  Predicted '1's: 89/100\n  Actual '1's:    100/100\n\nDeepSeek 3.1:\n  F1 Score:       0.9189\n  Precision:      1.0000\n  Recall:         0.8500\n  Accuracy:       0.8500\n  Predicted '1's: 85/100\n  Actual '1's:    100/100\n\nGPT-5:\n  F1 Score:       0.9247\n  Precision:      1.0000\n  Recall:         0.8600\n  Accuracy:       0.8600\n  Predicted '1's: 86/100\n  Actual '1's:    100/100\nThe f1 score is 0.9285714285714286.\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"## weighted ensemble from PAN CLEF\nget_weighted_score(coling_test_probs[pron_feats],coling_test['label'],total_preds[pron_feats],df['label'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T06:55:33.963383Z","iopub.execute_input":"2025-12-12T06:55:33.963924Z","iopub.status.idle":"2025-12-12T06:55:33.997208Z","shell.execute_reply.started":"2025-12-12T06:55:33.963887Z","shell.execute_reply":"2025-12-12T06:55:33.996428Z"}},"outputs":[{"name":"stdout","text":"COMPREHENSIVE MODEL PERFORMANCE\n================================================================================\n\nGemini:\n  F1 Score:       0.9637\n  Precision:      1.0000\n  Recall:         0.9300\n  Accuracy:       0.9300\n  Predicted '1's: 93/100\n  Actual '1's:    100/100\n\nDeepSeek 3.1:\n  F1 Score:       0.9848\n  Precision:      1.0000\n  Recall:         0.9700\n  Accuracy:       0.9700\n  Predicted '1's: 97/100\n  Actual '1's:    100/100\n\nGPT-5:\n  F1 Score:       0.9744\n  Precision:      1.0000\n  Recall:         0.9500\n  Accuracy:       0.9500\n  Predicted '1's: 95/100\n  Actual '1's:    100/100\nThe f1 score is 0.9743589743589743.\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"calculate_comprehensive_metrics(np.where(new_samples_test_preds_training_PAN[:,1]>0.5,1,0),df['label'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T06:59:57.424531Z","iopub.execute_input":"2025-12-12T06:59:57.425447Z","iopub.status.idle":"2025-12-12T06:59:57.455508Z","shell.execute_reply.started":"2025-12-12T06:59:57.425418Z","shell.execute_reply":"2025-12-12T06:59:57.454647Z"}},"outputs":[{"name":"stdout","text":"COMPREHENSIVE MODEL PERFORMANCE\n================================================================================\n\nGemini:\n  F1 Score:       0.9418\n  Precision:      1.0000\n  Recall:         0.8900\n  Accuracy:       0.8900\n  Predicted '1's: 89/100\n  Actual '1's:    100/100\n\nDeepSeek 3.1:\n  F1 Score:       0.9189\n  Precision:      1.0000\n  Recall:         0.8500\n  Accuracy:       0.8500\n  Predicted '1's: 85/100\n  Actual '1's:    100/100\n\nGPT-5:\n  F1 Score:       0.9247\n  Precision:      1.0000\n  Recall:         0.8600\n  Accuracy:       0.8600\n  Predicted '1's: 86/100\n  Actual '1's:    100/100\n","output_type":"stream"},{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"{'Gemini': {'f1': 0.9417989417989417,\n  'precision': 1.0,\n  'recall': 0.89,\n  'accuracy': 0.89,\n  'predicted_ones': 89,\n  'actual_ones': 100},\n 'DeepSeek 3.1': {'f1': 0.9189189189189189,\n  'precision': 1.0,\n  'recall': 0.85,\n  'accuracy': 0.85,\n  'predicted_ones': 85,\n  'actual_ones': 100},\n 'GPT-5': {'f1': 0.924731182795699,\n  'precision': 1.0,\n  'recall': 0.86,\n  'accuracy': 0.86,\n  'predicted_ones': 86,\n  'actual_ones': 100}}"},"metadata":{}}],"execution_count":63},{"cell_type":"code","source":"calculate_comprehensive_metrics(np.where(new_samples_test_preds_training_COLING[:,1]>0.5,1,0),df['label'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T07:01:12.190343Z","iopub.execute_input":"2025-12-12T07:01:12.190728Z","iopub.status.idle":"2025-12-12T07:01:12.221098Z","shell.execute_reply.started":"2025-12-12T07:01:12.190702Z","shell.execute_reply":"2025-12-12T07:01:12.220175Z"}},"outputs":[{"name":"stdout","text":"COMPREHENSIVE MODEL PERFORMANCE\n================================================================================\n\nGemini:\n  F1 Score:       0.9796\n  Precision:      1.0000\n  Recall:         0.9600\n  Accuracy:       0.9600\n  Predicted '1's: 96/100\n  Actual '1's:    100/100\n\nDeepSeek 3.1:\n  F1 Score:       0.9899\n  Precision:      1.0000\n  Recall:         0.9800\n  Accuracy:       0.9800\n  Predicted '1's: 98/100\n  Actual '1's:    100/100\n\nGPT-5:\n  F1 Score:       0.9796\n  Precision:      1.0000\n  Recall:         0.9600\n  Accuracy:       0.9600\n  Predicted '1's: 96/100\n  Actual '1's:    100/100\n","output_type":"stream"},{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"{'Gemini': {'f1': 0.9795918367346939,\n  'precision': 1.0,\n  'recall': 0.96,\n  'accuracy': 0.96,\n  'predicted_ones': 96,\n  'actual_ones': 100},\n 'DeepSeek 3.1': {'f1': 0.98989898989899,\n  'precision': 1.0,\n  'recall': 0.98,\n  'accuracy': 0.98,\n  'predicted_ones': 98,\n  'actual_ones': 100},\n 'GPT-5': {'f1': 0.9795918367346939,\n  'precision': 1.0,\n  'recall': 0.96,\n  'accuracy': 0.96,\n  'predicted_ones': 96,\n  'actual_ones': 100}}"},"metadata":{}}],"execution_count":64},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}